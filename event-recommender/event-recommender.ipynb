{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effortless models deployment with Mlflow\n",
    "\n",
    "## Creating an recommendation system model using a custom flavor in MLFlow\n",
    "\n",
    "In the examples provided before, we shown how, by simply adopting the MLFlow model specification to persist our models, we can then achieve easy deployments in a variety of platforms. All we had to do is to save the model using, for instance for a FastAI model, `mlflow.fastai.log_model` to save the model using the `MLModel` format. MlFlow supports the most popular frameworks out there.\n",
    "\n",
    "However, this technique has a bold implication: you can achieve everything you want to do using one single model flavor. It is certainly true that several frameworks like `TensorFlow` or `PyTorch` are flexible enough to be *modeling complete*, meaning that any modeling task we want to do can be achieved by using any of the building blocks they provide. However, it may not be necessary simple and it is very common to use the strengths of multiple frameworks in a single modeling task.\n",
    "\n",
    "For instance, you might find yourself using `scikit-learn` to do categorical encoding or missing values inputation to then feed the data to a `Keras` model. How can you log this kind of models in MLFlow? Is it one or the other?\n",
    "\n",
    "In this notebook, I will show you how you con combine multiple flavor in MLFlow to generate your own one to then, achieve the efortless model deployment we have been talking about. Also, this technique is useful to package the multiple pieces that are required to run a model, ensuring that all the dependencies are packaged correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demostrate this example, we will switch gears to a different modeling task: a recommender for events people can attend to. On this example we will try to build a recommender that will take an user and a history of the events they attended to and recommend 10 events they might be interested to attend to. We will save this model using MLFlow to then deploy it. Let's take a look:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset\n",
    "\n",
    "First, we will load the dataset. It is composed of two columns: 'user_id' and 'event_id':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getData():\n",
    "    train = pd.read_csv('train.csv')[['user_id', 'event_id']]\n",
    "    test = pd.read_csv('test.csv')[['user_id', 'event_id']]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1648064733656
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "train, test = getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we display our dataset we will see that both the training and testing datasets contains pairs of elements `user` and `event`, both encoded as GUIDs indicating that the given user picked the given event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>39e8d4e9-d3a6-47f3-aed1-4849908cb6ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>daaa51bc-e8bf-47c9-9268-a46de19ac7e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>6c0068fb-dc83-4dd1-a5b9-98210a5dd267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>40ce7f97-650e-4d3e-b7d3-b776673f4fc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>f426dff5-0e14-40ce-9489-45643982d99f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807800</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>0385ff2c-6c9a-4467-83b0-5aaf6b5a6c96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807801</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>f9388434-6056-4432-b25e-b933b22a4ff6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807802</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>768bcd5b-8c81-4ef0-80dc-cf65ddaf8c1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807803</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>798cfc47-0191-4d95-9f96-3babd7539cae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807804</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>9124e53e-2441-4309-b678-00aea408fbce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>807805 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     user_id  \\\n",
       "0       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "1       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "2       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "3       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "4       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "...                                      ...   \n",
       "807800  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "807801  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "807802  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "807803  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "807804  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "\n",
       "                                    event_id  \n",
       "0       39e8d4e9-d3a6-47f3-aed1-4849908cb6ba  \n",
       "1       daaa51bc-e8bf-47c9-9268-a46de19ac7e2  \n",
       "2       6c0068fb-dc83-4dd1-a5b9-98210a5dd267  \n",
       "3       40ce7f97-650e-4d3e-b7d3-b776673f4fc2  \n",
       "4       f426dff5-0e14-40ce-9489-45643982d99f  \n",
       "...                                      ...  \n",
       "807800  0385ff2c-6c9a-4467-83b0-5aaf6b5a6c96  \n",
       "807801  f9388434-6056-4432-b25e-b933b22a4ff6  \n",
       "807802  768bcd5b-8c81-4ef0-80dc-cf65ddaf8c1a  \n",
       "807803  798cfc47-0191-4d95-9f96-3babd7539cae  \n",
       "807804  9124e53e-2441-4309-b678-00aea408fbce  \n",
       "\n",
       "[807805 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 807805\n",
      "Testing size: 62700\n",
      "Unique users: 1113\n",
      "Unique items: 6235\n"
     ]
    }
   ],
   "source": [
    "print('Training size:', len(train))\n",
    "print('Testing size:', len(test))\n",
    "print('Unique users:', len(train['user_id'].unique()))\n",
    "print('Unique items:', len(train['event_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider that each interaction the user has with an item (an event) is equally important. This means that any person attending to any event is a signal as strong as any other person attending to any other event (hint: this implies that we are not capturing situations where a person attended to an event they didn't like). To capture that explicitly, we will create a new column in the dataset called `value` that will contain the number `1.0`, representing the weight of the interaction between an user and an event. Take into account that weighting is a very import aspect of a recommender and there are several ways of doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['value'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>39e8d4e9-d3a6-47f3-aed1-4849908cb6ba</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>daaa51bc-e8bf-47c9-9268-a46de19ac7e2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>6c0068fb-dc83-4dd1-a5b9-98210a5dd267</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>40ce7f97-650e-4d3e-b7d3-b776673f4fc2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>734eb5b3-9852-4456-8bab-86d507965f3d</td>\n",
       "      <td>f426dff5-0e14-40ce-9489-45643982d99f</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807800</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>0385ff2c-6c9a-4467-83b0-5aaf6b5a6c96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807801</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>f9388434-6056-4432-b25e-b933b22a4ff6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807802</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>768bcd5b-8c81-4ef0-80dc-cf65ddaf8c1a</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807803</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>798cfc47-0191-4d95-9f96-3babd7539cae</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807804</th>\n",
       "      <td>b91bc14d-347d-4aa4-81ba-b8391fdd8c2c</td>\n",
       "      <td>9124e53e-2441-4309-b678-00aea408fbce</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>807805 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     user_id  \\\n",
       "0       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "1       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "2       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "3       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "4       734eb5b3-9852-4456-8bab-86d507965f3d   \n",
       "...                                      ...   \n",
       "807800  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "807801  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "807802  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "807803  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "807804  b91bc14d-347d-4aa4-81ba-b8391fdd8c2c   \n",
       "\n",
       "                                    event_id  value  \n",
       "0       39e8d4e9-d3a6-47f3-aed1-4849908cb6ba    1.0  \n",
       "1       daaa51bc-e8bf-47c9-9268-a46de19ac7e2    1.0  \n",
       "2       6c0068fb-dc83-4dd1-a5b9-98210a5dd267    1.0  \n",
       "3       40ce7f97-650e-4d3e-b7d3-b776673f4fc2    1.0  \n",
       "4       f426dff5-0e14-40ce-9489-45643982d99f    1.0  \n",
       "...                                      ...    ...  \n",
       "807800  0385ff2c-6c9a-4467-83b0-5aaf6b5a6c96    1.0  \n",
       "807801  f9388434-6056-4432-b25e-b933b22a4ff6    1.0  \n",
       "807802  768bcd5b-8c81-4ef0-80dc-cf65ddaf8c1a    1.0  \n",
       "807803  798cfc47-0191-4d95-9f96-3babd7539cae    1.0  \n",
       "807804  9124e53e-2441-4309-b678-00aea408fbce    1.0  \n",
       "\n",
       "[807805 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users and events are encoded as GUIDs in our dataset, and that's what probably we will get as inputs when we deploy this model in production. However, ML models won't work with this kind of data. We will have to transform these two columns to categorical values so we can use them in our recommender. There are multiple ways to achieve this, but using `OrdinalEncoder` is probably one of the easier ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "train['user_id'] = users_encoder.fit_transform(train['user_id'].values.reshape(-1,1))\n",
    "\n",
    "items_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "train['event_id'] = items_encoder.fit_transform(train['event_id'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are creating encoders for both items and users, cause both of them uses GUIDs. Pay attention around how `OrdinalEncoder` is configured, particularly:\n",
    "\n",
    "- `handle_unknown` is set to `use_encoded_value`, meaning that if the encoder has to encode a new value that was not seen in the training set, it will use a predefined value to denote that. This is useful in the case that new items/users are added to the platform for which the model is not that useful.\n",
    "- `unknown_value` is set to `np.nan`. This will be our missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You will see later way `OrdinalEncoder` is an smart choice, specially when working with sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to create our training dataset. We will use here the library `implicit`, which contains several implementations of recommendation system's algorithmn. An important details about the library `implicit` is that it requires us to provide the data as sparse matrices. Sparse matrices are an efficient way to represent matrices that contains a high number of zeros. They also help on doing computation on them more efficient (at expenses of some other operations being more costly). Recommendation systems tent to deal with datasets that exploit this fact a lot.\n",
    "\n",
    "We need to construct a matrix of shape `(#EVENTS, #USERS)` where a value of `1` in row `EVENT` and column `USER` means that the user in position `USER` has attended to event in position `EVENT`. Since our `OrdinalEncoder` provides us with values in the range of `[0..#USERS]` for users and `[0..#EVENTS]` for events, the encoded value represents a convenient way to populate this matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1648071658359
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "sparse_event_user_train = sparse.csr_matrix((train['value'],\n",
    "                                            (train['event_id'].astype(int), train['user_id'].astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes: Type casting is require for `csr_matrix`. Matrix indeces are integers while its values should be float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's check the shape of the training matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1648070667974
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6235, 1113)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_event_user_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches the number of users and events we had before. Now, let's create our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1648067044391
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "als_model = AlternatingLeastSquares(factors=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will construct a model using the algorithm Alternating Least Squares, with a latent space of 100 factors. The implementation corresponds to the paper [Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering](https://dl.acm.org/doi/10.1145/2043932.2043987). Going over the details of the algorithm is out of our scope but you are more than welcome to read the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1648067566341
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45457f1a9a0447549ef57566ca8a5eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_model.fit(sparse_event_user_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to evaluate the performance of the model to have an understanding about how good or bad it is. There are several ways to measure the performance of a recommender. In this case we will pay attention to Precision@K. This metric is an extension of the the metric Precision but extended to a recommender scenario. While precision measures \"*Out of the items predicted to be relevant, how many are truly relevant?*\", Precision@k measures \"*Out of the top k items predicted to be relevant for each user, how many are truly relevant for the user?*\". As you can see, this metric is very relevant in a recommender settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get that done, let's start by preparing our testing dataset. It's shape is basically the same one that the one we used for training. In order to be consistent, it is important to apply the same categorical encoding to the elements in the testing set that we did in the training set.\n",
    "\n",
    "Our `OrdinalEncoder` does this job very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['event_id'] = items_encoder.transform(test['event_id'].values.reshape(-1,1))\n",
    "test['user_id'] = users_encoder.transform(test['user_id'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same weighting schema we used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['value'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some users or items in the testing set may never been seen in the training set and hence we know nothing about them. As a consequence, we can't recommend anything about them. We will drop them. In reality, we should pick an strategy to deal with them, but that's a battle for tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the training phase, the evaluation also requires data to be supplied as sparse matrices. Again, our `OrdinalEncoder` is very handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_event_user_test = sparse.csr_matrix((test['value'],\n",
    "                                           (test['event_id'].astype(int),test['user_id'].astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6187, 1112)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_event_user_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to run our evaluation routines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from implicit import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51b311f95094416ba7cc1fc48bb421c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "pk10 = evaluation.mean_average_precision_at_k(als_model, sparse_event_user_train, sparse_event_user_test, K=10)\n",
    "print(pk10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric('precision_10', pk10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This means that 88% of the time, our model predicts something that is relevant for the user. That's not bad considering the amount of effort we put in building the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc60de9acdb94384ae44e04bd4aeee7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6832641519691369\n"
     ]
    }
   ],
   "source": [
    "auc10 = evaluation.AUC_at_k(als_model, sparse_event_user_train, sparse_event_user_test)\n",
    "print(auc10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric('auc_10', auc10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the recommend method from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to see how we can actually use this model in production. To generate recomendations for a given user we can use the method `recommend` from the model. The method `recommend` requires an sparse matrix as input indicating the items that the user already selected. We can construct this information in the following way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reload our initial data so we can demostrate how to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will pick a sample user randomly to showcase this (random... well, I will pick the one at position 0 :D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8c6b414e-b79a-418d-8948-7ffb7538cbd9\n"
     ]
    }
   ],
   "source": [
    "sample_user_id = test['user_id'][0]\n",
    "print(sample_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `recommend` requires to know which are the items the user already selected. In this example, we will consider the items from the training set, so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user_items = train[train['user_id'] ==  sample_user_id].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a couple of things now:\n",
    "\n",
    "- Encode the user ID in the same way we did before, again using our `OrdinalEncoder`.\n",
    "- Encode the events ID in the same way we did before, again using our `OrdinalEncoder`.\n",
    "- Weight the items in the same way we did before, `1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user_items['user_id'] = users_encoder.transform(sample_user_items['user_id'].values.reshape(-1, 1))\n",
    "sample_user_items['event_id'] = items_encoder.transform(sample_user_items['event_id'].values.reshape(-1,1))\n",
    "sample_user_items['value'] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user we are working with has the following ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612\n"
     ]
    }
   ],
   "source": [
    "sample_user = int(sample_user_items['user_id'].iloc[0])\n",
    "print(sample_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, our model most of the time works with sparse matrices and this is also the case for the method `recommend`. So we will provide this data using an sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = sparse.csr_matrix((sample_user_items['value'],\n",
    "                          (np.zeros(len(sample_user_items), dtype=int), sample_user_items['event_id'].astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What is `np.zeros` doing here?** The recommend method requires to provide sparse vectors for the items already liked for the user. `np.zeros` is just creating an array with all zeros of lenght `len(sample_user_items)` - which is the amount of items the user selected. This indicates that the items correspond to the same user, being in this case represented by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6235)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the method now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1648071123321
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ids, scores = als_model.recommend([sample_user], user_items=items, \n",
    "                                  N=10, filter_already_liked_items=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a9e233a-0b96-4031-8984-f66d527f31c5</td>\n",
       "      <td>1.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21d373ca-daf7-4225-87d2-56c04dff1e3e</td>\n",
       "      <td>1.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f9e2891-373a-419f-8e8c-32ad21e03121</td>\n",
       "      <td>1.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0f47dc95-d034-4418-8afe-6bf452f7cea3</td>\n",
       "      <td>1.000653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159b7b72-a5fd-4233-9fb9-15c1c55fb40e</td>\n",
       "      <td>1.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1bca8b70-a1c8-419d-b748-b1b7afa73f2b</td>\n",
       "      <td>1.000597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09ce03da-e4a6-4129-bc0c-fa49bb0184d1</td>\n",
       "      <td>1.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>217981b1-d95f-4f46-9aed-5796e8249c1b</td>\n",
       "      <td>1.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0b7df7af-b8e2-4c0b-b27c-d3094b02dc84</td>\n",
       "      <td>1.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10069266-e0c0-40c7-9ed7-737f14036762</td>\n",
       "      <td>1.000466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               event_id     score\n",
       "0  1a9e233a-0b96-4031-8984-f66d527f31c5  1.000906\n",
       "1  21d373ca-daf7-4225-87d2-56c04dff1e3e  1.000863\n",
       "2  0f9e2891-373a-419f-8e8c-32ad21e03121  1.000739\n",
       "3  0f47dc95-d034-4418-8afe-6bf452f7cea3  1.000653\n",
       "4  159b7b72-a5fd-4233-9fb9-15c1c55fb40e  1.000631\n",
       "5  1bca8b70-a1c8-419d-b748-b1b7afa73f2b  1.000597\n",
       "6  09ce03da-e4a6-4129-bc0c-fa49bb0184d1  1.000590\n",
       "7  217981b1-d95f-4f46-9aed-5796e8249c1b  1.000496\n",
       "8  0b7df7af-b8e2-4c0b-b27c-d3094b02dc84  1.000494\n",
       "9  10069266-e0c0-40c7-9ed7-737f14036762  1.000466"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"event_id\": items_encoder.inverse_transform(ids.reshape(-1,1)).reshape(-1), \n",
    "              \"score\": scores.reshape(-1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Too much reshape?** Yes, I know, there is a lot. But `OrdinalEncoder` required 2-D arrays so the first `reshape` call you see converts a 1-D array to a 2-D one, and the second one converts it back to a single dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we talk now about MLFlow? \n",
    "\n",
    "Now let's get back to business. How we can package this model using MLflow so it is simple to deploy it? I picked this example because it has a lot of interesting pieces which makes it very appeling. Our model now contains elements from `scikit-learn` and elements from another framework that it is not even supported by MLFlow by default, `implicit`. So how can we proceed?\n",
    "\n",
    "One option, of course it's to package everything using Scikit-Learn pipelines and then log the model using the `scikit` flavor. It will work, but we are looking for a more flexible approach now. One approach that can be useful here is to create our own flavor:\n",
    "\n",
    "### Creating a custom model in MLFlow\n",
    "\n",
    "In my last post I introduced the flavor `pyfunc` that MLFlow uses to run models at deployment time. We saw a way to customize how our model is loaded and inference is run by providing a custom model loader module. However, `pyfunc` also provides a way to create our own custom flavor, that can be composed of whatever elements we want. To do that MLFlow requires us to do 2 thing:\n",
    "\n",
    "- Create a class representing our model, that inherets from `PythoModel`.\n",
    "- Implement in this class the method `load_context` and `predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this looks like. The class should look like the following:\n",
    "\n",
    "```python\n",
    "class AlternatingLeastSquaresModel(PythonModel):\n",
    "    def __init__(self, ...)\n",
    "        (...)\n",
    "\n",
    "    def load_context(self, context: PythonModelContext):\n",
    "        (..)\n",
    "\n",
    "    def predict(self, context: PythonModelContext, data):\n",
    "        (...)\n",
    "```\n",
    "\n",
    "Let's go over this in details:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The init method\n",
    "\n",
    "We will use the constructor to instantiate the model. This is our chance to include in the model all the elements we want to compose it. For instance we can pass here:\n",
    "\n",
    "- The number of items we want to recommend.\n",
    "- The model we trained\n",
    "- The items and user's encoders\n",
    "\n",
    "```python\n",
    "def __init__(self, \n",
    "             recommender: AlternatingLeastSquares, \n",
    "             item2id: OrdinalEncoder,\n",
    "             user2id: OrdinalEncoder,\n",
    "             k: int = 10):\n",
    "\n",
    "    self.model = recommender\n",
    "    self._k = k\n",
    "    self._item2id = item2id\n",
    "    self._user2id = user2id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The load_context method\n",
    "\n",
    "This method allows you to load any additional asset that you might need. For instance, let's consider the case where the user mappings are stored in a file, a json file for instance. Another typical case would be when you model weights are persisted, let's say, in weights file like `h5`, `pt`, etc. You can load this files here. MLFlow can persist these files and load them on runtime in this point.\n",
    "\n",
    "In `context.artifacts['artifact_key']` you will find the path to the specific artifact. For instance, let's imagine our model is a Keras model, and we have our model persisted in `h5` format, then `context.artifacts['model']` can be a pointer to the file `model.h5` that you can use to the call `model.load(model_path)` in Keras.\n",
    "\n",
    "We will skip this step cause our model doesn't require it.\n",
    "\n",
    "```python\n",
    "def load_context(self, context: PythonModelContext):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The predict method\n",
    "\n",
    "The predict method is what get's called each time MLFLow runs our model. The signature is pretty similar to what you would expect, but there is also a `PythonModelContext` passed as argument. This is the same configuration that get's passed to you in the `load_context` method in case you need it. It's rarely the case you will need this on the predict, but it is there just in case.\n",
    "\n",
    "The `data` parameter is where you input data is passed. The type of this argument will depend on the signature you define for your model. In our case, I will require this data to be columnar, so it will be `pd.DataFrame`. The return type should also comply with the signature. Again, in our case we will be returning a table with the recommendations so it will be `pd.DataFrame`.\n",
    "\n",
    "What happens inside the method is almost the same we did before when we esay how to run the `recommend` method. However, if you see, now we are using the `OrdinalEncoder` objects instanciated in the `AlternatingLeastSquaresModel`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.pyfunc import PythonModel, PythonModelContext\n",
    "from typing import Dict\n",
    "\n",
    "class AlternatingLeastSquaresModel(PythonModel):\n",
    "    def __init__(self, \n",
    "                 recommender: AlternatingLeastSquares, \n",
    "                 item2id: OrdinalEncoder,\n",
    "                 user2id: OrdinalEncoder,\n",
    "                 k: int = 10):\n",
    "        \n",
    "        self.model = recommender\n",
    "        self._k = k\n",
    "        self._item2id = item2id\n",
    "        self._user2id = user2id\n",
    "\n",
    "    def load_context(self, context: PythonModelContext):\n",
    "        pass\n",
    "\n",
    "    def predict(self, context: PythonModelContext, data):\n",
    "        # Inputs are dataframes with 2 columns, `user_id` containing the user to run the recommendations\n",
    "        # and `event_id` containing the items the user already picked. Notice that the user is repeated\n",
    "        # multiple time per each event so we can have a tabular input data.\n",
    "        # We make a copy of the dataframe cause we will modify it.\n",
    "        data = data.copy()\n",
    "        \n",
    "        # Convert GUIDs to the IDs we used for training\n",
    "        data['event_id'] = self._item2id.transform(data['event_id'].values.reshape(-1,1))\n",
    "        data['user_id'] = self._user2id.transform(data['user_id'].values.reshape(-1,1))\n",
    "        \n",
    "        # Use the same weighting schema we used for training\n",
    "        data['value'] = 1.0\n",
    "        \n",
    "        # Drop NAs that will be generated for events not included in the training dataset we don't know\n",
    "        # anything about.\n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "        # The user we will recommend for\n",
    "        users = data['user_id'].astype('int').unique()\n",
    "        \n",
    "        # Items picked by the user as an sparse matrix.\n",
    "        items = sparse.csr_matrix((data['value'],\n",
    "                                  (np.zeros(len(sample_user_items), dtype=int), data['event_id'].astype(int))))\n",
    "        \n",
    "        # Run the recomendations\n",
    "        ids, scores = self.model.recommend(users,\n",
    "                                           user_items=items, \n",
    "                                           N=self._k,\n",
    "                                           filter_already_liked_items=False)\n",
    "        \n",
    "        # Return the output as a dataframe\n",
    "        return pd.DataFrame({\n",
    "            \"event_id\": self._item2id.inverse_transform(ids.reshape(-1,1)).reshape(-1), \n",
    "            \"score\": scores.reshape(-1)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow_model = AlternatingLeastSquaresModel(als_model, item2id = items_encoder, user2id = users_encoder, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the `predict` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user_items = train[train['user_id'] ==  sample_user_id].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mlflow_model.predict(None, sample_user_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You will notice I'm passing `None` for the argument `context`. This is just for testing, but in runtime, when the model is deployed using MLFlow, this will have the actual context object for the model. We won't pass the parameter directly, cause it will be passed automatically by MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a9e233a-0b96-4031-8984-f66d527f31c5</td>\n",
       "      <td>1.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21d373ca-daf7-4225-87d2-56c04dff1e3e</td>\n",
       "      <td>1.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f9e2891-373a-419f-8e8c-32ad21e03121</td>\n",
       "      <td>1.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0f47dc95-d034-4418-8afe-6bf452f7cea3</td>\n",
       "      <td>1.000653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159b7b72-a5fd-4233-9fb9-15c1c55fb40e</td>\n",
       "      <td>1.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1bca8b70-a1c8-419d-b748-b1b7afa73f2b</td>\n",
       "      <td>1.000597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09ce03da-e4a6-4129-bc0c-fa49bb0184d1</td>\n",
       "      <td>1.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>217981b1-d95f-4f46-9aed-5796e8249c1b</td>\n",
       "      <td>1.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0b7df7af-b8e2-4c0b-b27c-d3094b02dc84</td>\n",
       "      <td>1.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10069266-e0c0-40c7-9ed7-737f14036762</td>\n",
       "      <td>1.000466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               event_id     score\n",
       "0  1a9e233a-0b96-4031-8984-f66d527f31c5  1.000906\n",
       "1  21d373ca-daf7-4225-87d2-56c04dff1e3e  1.000863\n",
       "2  0f9e2891-373a-419f-8e8c-32ad21e03121  1.000739\n",
       "3  0f47dc95-d034-4418-8afe-6bf452f7cea3  1.000653\n",
       "4  159b7b72-a5fd-4233-9fb9-15c1c55fb40e  1.000631\n",
       "5  1bca8b70-a1c8-419d-b748-b1b7afa73f2b  1.000597\n",
       "6  09ce03da-e4a6-4129-bc0c-fa49bb0184d1  1.000590\n",
       "7  217981b1-d95f-4f46-9aed-5796e8249c1b  1.000496\n",
       "8  0b7df7af-b8e2-4c0b-b27c-d3094b02dc84  1.000494\n",
       "9  10069266-e0c0-40c7-9ed7-737f14036762  1.000466"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got what we expected. Let's now save the model using this our custom flavor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging the model with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we will log the model using the method `mlflow.pyfunc.log_model()`. But first, let's define our signature. Remember we have two ways to do this, using the `infer_signature` method and supplying a sample of the input and the output, or creating that manually.\n",
    "\n",
    "Using `infer_signature`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['user_id': string, 'event_id': string]\n",
       "outputs: \n",
       "  ['event_id': string, 'score': float]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "signature = infer_signature(train[['user_id', 'event_id']], data)\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `ColSpec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['user_id': string, 'event_id': string]\n",
       "outputs: \n",
       "  ['event_id': string, 'score': float]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import ColSpec, DataType, Schema\n",
    "\n",
    "signature = ModelSignature(\n",
    "    inputs=Schema([\n",
    "        ColSpec(DataType.string, \"user_id\"),\n",
    "        ColSpec(DataType.string, \"event_id\")\n",
    "    ]), \n",
    "    outputs=Schema([\n",
    "        ColSpec(DataType.string, \"event_id\"),\n",
    "        ColSpec(DataType.float, \"score\")\n",
    "    ]))\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'event_recommender' already exists. Creating a new version of this model...\n",
      "2022/04/05 22:19:41 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: event_recommender, version 4\n",
      "Created version '4' of model 'event_recommender'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelInfo(artifact_path='recommender', flavors={'python_function': {'cloudpickle_version': '2.0.0', 'python_model': 'python_model.pkl', 'loader_module': 'mlflow.pyfunc.model', 'python_version': '3.8.8', 'env': 'conda.yaml'}}, model_uri='runs:/f8845fed-a4bf-45da-9e57-b996d9da442f/recommender', model_uuid='ccefda98165745c79bfb48566026f0bc', run_id='f8845fed-a4bf-45da-9e57-b996d9da442f', saved_input_example_info=None, signature_dict={'inputs': '[{\"name\": \"user_id\", \"type\": \"string\"}, {\"name\": \"event_id\", \"type\": \"string\"}]', 'outputs': '[{\"name\": \"event_id\", \"type\": \"string\"}, {\"name\": \"score\", \"type\": \"float\"}]'}, utc_time_created='2022-04-05 22:18:11.440174')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pyfunc.log_model(\"recommender\", \n",
    "                        python_model=mlflow_model,\n",
    "                        signature=signature,\n",
    "                        registered_model_name='event_recommender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore this arguments:\n",
    "\n",
    "- `\"recommender\"` is just the name of the folder where the artifacts will be stored. It can be any name.\n",
    "- `python_model` is the instance of the class that inherits from `PythonModel`. Pay special attention that this object will be serialized using the `Pickle` format and then loaded into memory in runtime.\n",
    "- `signature` is the model input and output signature, as usual.\n",
    "- `registered_model_name` is the name of the model we will register in the model registry. Remember that this parameter is optional and you should only include it when you want the model to be registered in the registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testig the MLFlow model\n",
    "\n",
    "We can load the model from the code using the following line. In this case we are assuming the model was registered using the name `event_recommender`. We are also retrieving the last version of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri = \"azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/18522758-626e-4d88-92ac-dc9c7a5c26d4/resourceGroups/Analytics.Aml.Experiments.Workspaces/providers/Microsoft.MachineLearningServices/workspaces/aa-ml-aml-workspace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/20 20:20:44 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 2.1.0, required: cloudpickle==2.0.0)\n",
      " - ipython (current: 8.3.0, required: ipython==7.22.0)\n",
      " - scikit-learn (current: 1.1.1, required: scikit-learn==1.0.2)\n",
      " - typing-extensions (current: uninstalled, required: typing-extensions==3.7.4.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2022/05/20 20:20:44 WARNING mlflow.pyfunc: The version of CloudPickle that was used to save the model, `CloudPickle 2.0.0`, differs from the version of CloudPickle that is currently running, `CloudPickle 2.1.0`, and may be incompatible\n",
      "/home/santiagxf/miniconda3/envs/event-recommender/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model('models:/event_recommender/latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the `predict` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user_items = train[train['user_id'] ==  sample_user_id].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.predict(sample_user_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159b7b72-a5fd-4233-9fb9-15c1c55fb40e</td>\n",
       "      <td>1.003558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10069266-e0c0-40c7-9ed7-737f14036762</td>\n",
       "      <td>1.003018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a9e233a-0b96-4031-8984-f66d527f31c5</td>\n",
       "      <td>1.002954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27dfc792-00cb-42aa-9613-748cabb9be29</td>\n",
       "      <td>1.002925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1bca8b70-a1c8-419d-b748-b1b7afa73f2b</td>\n",
       "      <td>1.002875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0b7df7af-b8e2-4c0b-b27c-d3094b02dc84</td>\n",
       "      <td>1.002443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0f47dc95-d034-4418-8afe-6bf452f7cea3</td>\n",
       "      <td>1.002399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0f9e2891-373a-419f-8e8c-32ad21e03121</td>\n",
       "      <td>1.002333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>217981b1-d95f-4f46-9aed-5796e8249c1b</td>\n",
       "      <td>1.002129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>09ce03da-e4a6-4129-bc0c-fa49bb0184d1</td>\n",
       "      <td>1.001551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               event_id     score\n",
       "0  159b7b72-a5fd-4233-9fb9-15c1c55fb40e  1.003558\n",
       "1  10069266-e0c0-40c7-9ed7-737f14036762  1.003018\n",
       "2  1a9e233a-0b96-4031-8984-f66d527f31c5  1.002954\n",
       "3  27dfc792-00cb-42aa-9613-748cabb9be29  1.002925\n",
       "4  1bca8b70-a1c8-419d-b748-b1b7afa73f2b  1.002875\n",
       "5  0b7df7af-b8e2-4c0b-b27c-d3094b02dc84  1.002443\n",
       "6  0f47dc95-d034-4418-8afe-6bf452f7cea3  1.002399\n",
       "7  0f9e2891-373a-419f-8e8c-32ad21e03121  1.002333\n",
       "8  217981b1-d95f-4f46-9aed-5796e8249c1b  1.002129\n",
       "9  09ce03da-e4a6-4129-bc0c-fa49bb0184d1  1.001551"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving the model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the model in an inference server locally in our local compute. Again, with this we can check that our deployment strategy will work. \n",
    "\n",
    "To do so, let's serve our model using mlflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "mlflow models serve -m models:/event_recommender/latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a sample request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"sample.json\", \"w\") as f:\n",
    "    f.write(sample_user_items.reset_index(drop=True).to_json(orient='split', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note how the model inputs is indicated. MLFlow requires the inputs to the model to be submitted using `JSON` format and multiple specification are supported. In the Cats vs Dogs sample we saw before we used the TensorFlow Serving specification. Now, since we are using tabular data, we can use the Columnar format in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"event_id\": \"1a9e233a-0b96-4031-8984-f66d527f31c5\", \"score\": 1.0018339157104492}, {\"event_id\": \"10069266-e0c0-40c7-9ed7-737f14036762\", \"score\": 1.0017820596694946}, {\"event_id\": \"0b7df7af-b8e2-4c0b-b27c-d3094b02dc84\", \"score\": 1.0017375946044922}, {\"event_id\": \"0f9e2891-373a-419f-8e8c-32ad21e03121\", \"score\": 1.0016436576843262}, {\"event_id\": \"09ce03da-e4a6-4129-bc0c-fa49bb0184d1\", \"score\": 1.001570701599121}, {\"event_id\": \"27dfc792-00cb-42aa-9613-748cabb9be29\", \"score\": 1.001529574394226}, {\"event_id\": \"1e22c59f-7542-4ccd-8630-cc387a7c5947\", \"score\": 1.0014907121658325}, {\"event_id\": \"1bca8b70-a1c8-419d-b748-b1b7afa73f2b\", \"score\": 1.0013089179992676}, {\"event_id\": \"159b7b72-a5fd-4233-9fb9-15c1c55fb40e\", \"score\": 1.001258373260498}, {\"event_id\": \"217981b1-d95f-4f46-9aed-5796e8249c1b\", \"score\": 1.0012205839157104}]"
     ]
    }
   ],
   "source": [
    "!cat -A sample.json | curl http://127.0.0.1:5000/invocations \\\n",
    "                        --request POST \\\n",
    "                        --header 'Content-Type: application/json' \\\n",
    "                        --data-binary @-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying to Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_deploy_client(\"azureml:/..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "deploy_config = {\n",
    "  \"computeType\": \"aci\",\n",
    "  \"containerResourceRequirements\": \n",
    "  {\n",
    "    \"cpu\": 2,\n",
    "    \"memoryInGB\": 4 \n",
    "  }\n",
    "}\n",
    "\n",
    "deployment_config_path = \"deployment_config.json\"\n",
    "with open(deployment_config_path, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(deploy_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webservice = client.create_deployment(model_uri=f'models:/event_recommender/4',\n",
    "                                      name=\"event-recommender-10\",\n",
    "                                      config={'deploy-config-file': deployment_config_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"sample.json\", \"w\") as f:\n",
    "    f.write('{ \"input_data\": ' + sample_user_items.reset_index(drop=True).to_json(orient='split') + '}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"event_id\": \"1a9e233a-0b96-4031-8984-f66d527f31c5\", \"score\": 1.0018339157104492}, {\"event_id\": \"10069266-e0c0-40c7-9ed7-737f14036762\", \"score\": 1.0017820596694946}, {\"event_id\": \"0b7df7af-b8e2-4c0b-b27c-d3094b02dc84\", \"score\": 1.0017375946044922}, {\"event_id\": \"0f9e2891-373a-419f-8e8c-32ad21e03121\", \"score\": 1.0016436576843262}, {\"event_id\": \"09ce03da-e4a6-4129-bc0c-fa49bb0184d1\", \"score\": 1.001570701599121}, {\"event_id\": \"27dfc792-00cb-42aa-9613-748cabb9be29\", \"score\": 1.001529574394226}, {\"event_id\": \"1e22c59f-7542-4ccd-8630-cc387a7c5947\", \"score\": 1.0014907121658325}, {\"event_id\": \"1bca8b70-a1c8-419d-b748-b1b7afa73f2b\", \"score\": 1.0013089179992676}, {\"event_id\": \"159b7b72-a5fd-4233-9fb9-15c1c55fb40e\", \"score\": 1.001258373260498}, {\"event_id\": \"217981b1-d95f-4f46-9aed-5796e8249c1b\", \"score\": 1.0012205839157104}]"
     ]
    }
   ],
   "source": [
    "!cat -A sample.json | curl https://event-recommender.eastus.inference.ml.azure.com/score \\\n",
    "                    --request POST \\\n",
    "                    --header 'Content-Type: application/json' \\\n",
    "                    --header 'Authorization: Bearer 2zU7eE3hu6At0J0mtkQQDtxNaFiHtbGt' \\\n",
    "                    --data-binary @-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus extra: Scoring multiple users at a time\n",
    "\n",
    "If you pay closer look to the model we created, you will see that it will only be able to score one user at a time. Usually, it can be more efficient to score multiple users at the time, specially if you run the model on hardware with multiple cores. Some changes are required to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.pyfunc import PythonModel, PythonModelContext\n",
    "\n",
    "class AlternatingLeastSquaresModel(PythonModel):\n",
    "    def __init__(self, \n",
    "                 recommender: AlternatingLeastSquares, \n",
    "                 item2id: OrdinalEncoder,\n",
    "                 user2id: OrdinalEncoder,\n",
    "                 k: int = 10):\n",
    "        \n",
    "        self.model = recommender\n",
    "        self._item2id = item2id\n",
    "        self._user2id = user2id\n",
    "        self._k = k\n",
    "\n",
    "    def load_context(self, context: PythonModelContext):\n",
    "        pass\n",
    "\n",
    "    def predict(self, context: PythonModelContext, data):\n",
    "        data = data.copy()\n",
    "        \n",
    "        data['user_cat'] = data['user_id'].astype('category')\n",
    "        data['event_id'] = self._item2id.transform(data['event_id'].values.reshape(-1,1))\n",
    "        data['user_id'] = self._user2id.transform(data['user_id'].values.reshape(-1,1))\n",
    "        data['value'] = 1.0\n",
    "        \n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "        items = sparse.csr_matrix((data['value'].astype(float),\n",
    "                                  (data['user_cat'].cat.codes, data['event_id'].astype(int))))\n",
    "        \n",
    "        ids, scores = self.model.recommend(data['user_id'].astype('int').unique(),\n",
    "                                           user_items=items, \n",
    "                                           N=self._k,\n",
    "                                           filter_already_liked_items=False)\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            \"user_id\": np.repeat(data['user_cat'].cat.categories, self._k),\n",
    "            \"event_id\": self._item2id.inverse_transform(ids.reshape(-1,1)).reshape(-1), \n",
    "            \"score\": scores.reshape(-1)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an instance of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_model = AlternatingLeastSquaresModel(als_model, item2id = items_encoder, user2id = users_encoder, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signature for this model would be then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['user_id': string, 'event_id': string]\n",
       "outputs: \n",
       "  ['user_id': string, 'event_id': string, 'score': float]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import ColSpec, DataType, Schema\n",
    "\n",
    "signature = ModelSignature(\n",
    "    inputs=Schema([\n",
    "        ColSpec(DataType.string, \"user_id\"),\n",
    "        ColSpec(DataType.string, \"event_id\")\n",
    "    ]), \n",
    "    outputs=Schema([\n",
    "        ColSpec(DataType.string, \"user_id\"),\n",
    "        ColSpec(DataType.string, \"event_id\"),\n",
    "        ColSpec(DataType.float, \"score\")\n",
    "    ]))\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can log the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'event_recommender_mutiuser'.\n",
      "2022/04/04 21:50:38 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: event_recommender_mutiuser, version 1\n",
      "Created version '1' of model 'event_recommender_mutiuser'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelInfo(artifact_path='recommender', flavors={'python_function': {'cloudpickle_version': '2.0.0', 'python_model': 'python_model.pkl', 'loader_module': 'mlflow.pyfunc.model', 'python_version': '3.8.8', 'env': 'conda.yaml'}}, model_uri='runs:/d1076159-8e9f-4bfb-8de5-f15c2be3afb3/recommender', model_uuid='b2d57331fbbf49ae9c25150f97dd8f1e', run_id='d1076159-8e9f-4bfb-8de5-f15c2be3afb3', saved_input_example_info=None, signature_dict={'inputs': '[{\"name\": \"user_id\", \"type\": \"string\"}, {\"name\": \"event_id\", \"type\": \"string\"}]', 'outputs': '[{\"name\": \"user_id\", \"type\": \"string\"}, {\"name\": \"event_id\", \"type\": \"string\"}, {\"name\": \"score\", \"type\": \"float\"}]'}, utc_time_created='2022-04-04 21:50:33.460556')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pyfunc.log_model(\"recommender\", \n",
    "                        python_model=mlflow_model,\n",
    "                        signature=signature,\n",
    "                        registered_model_name='event_recommender_mutiuser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model('models:/event_recommender_mutiuser/latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the `predict` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00115a30-da72-4ff7-a19d-b8dfa370ed6b</td>\n",
       "      <td>1a9e233a-0b96-4031-8984-f66d527f31c5</td>\n",
       "      <td>1.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00115a30-da72-4ff7-a19d-b8dfa370ed6b</td>\n",
       "      <td>10069266-e0c0-40c7-9ed7-737f14036762</td>\n",
       "      <td>1.001782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00115a30-da72-4ff7-a19d-b8dfa370ed6b</td>\n",
       "      <td>0b7df7af-b8e2-4c0b-b27c-d3094b02dc84</td>\n",
       "      <td>1.001738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115a30-da72-4ff7-a19d-b8dfa370ed6b</td>\n",
       "      <td>0f9e2891-373a-419f-8e8c-32ad21e03121</td>\n",
       "      <td>1.001644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00115a30-da72-4ff7-a19d-b8dfa370ed6b</td>\n",
       "      <td>09ce03da-e4a6-4129-bc0c-fa49bb0184d1</td>\n",
       "      <td>1.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>ffdfceac-37cd-484b-b3ab-b2aa0a76fb19</td>\n",
       "      <td>2b4c1b4e-9fa4-4a62-aebd-a6af36663cb4</td>\n",
       "      <td>1.003394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>ffdfceac-37cd-484b-b3ab-b2aa0a76fb19</td>\n",
       "      <td>216483f0-dc39-4269-a0e4-42d8689bd75e</td>\n",
       "      <td>1.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>ffdfceac-37cd-484b-b3ab-b2aa0a76fb19</td>\n",
       "      <td>10aaa832-7334-4e34-805c-87a64adcbc38</td>\n",
       "      <td>1.002810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>ffdfceac-37cd-484b-b3ab-b2aa0a76fb19</td>\n",
       "      <td>07987522-106e-4470-bdce-a346faa17bc8</td>\n",
       "      <td>1.002783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>ffdfceac-37cd-484b-b3ab-b2aa0a76fb19</td>\n",
       "      <td>2a3a1d34-9d24-43c2-8968-cb8d035f95c1</td>\n",
       "      <td>1.002448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6270 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   user_id  \\\n",
       "0     00115a30-da72-4ff7-a19d-b8dfa370ed6b   \n",
       "1     00115a30-da72-4ff7-a19d-b8dfa370ed6b   \n",
       "2     00115a30-da72-4ff7-a19d-b8dfa370ed6b   \n",
       "3     00115a30-da72-4ff7-a19d-b8dfa370ed6b   \n",
       "4     00115a30-da72-4ff7-a19d-b8dfa370ed6b   \n",
       "...                                    ...   \n",
       "6265  ffdfceac-37cd-484b-b3ab-b2aa0a76fb19   \n",
       "6266  ffdfceac-37cd-484b-b3ab-b2aa0a76fb19   \n",
       "6267  ffdfceac-37cd-484b-b3ab-b2aa0a76fb19   \n",
       "6268  ffdfceac-37cd-484b-b3ab-b2aa0a76fb19   \n",
       "6269  ffdfceac-37cd-484b-b3ab-b2aa0a76fb19   \n",
       "\n",
       "                                  event_id     score  \n",
       "0     1a9e233a-0b96-4031-8984-f66d527f31c5  1.001834  \n",
       "1     10069266-e0c0-40c7-9ed7-737f14036762  1.001782  \n",
       "2     0b7df7af-b8e2-4c0b-b27c-d3094b02dc84  1.001738  \n",
       "3     0f9e2891-373a-419f-8e8c-32ad21e03121  1.001644  \n",
       "4     09ce03da-e4a6-4129-bc0c-fa49bb0184d1  1.001571  \n",
       "...                                    ...       ...  \n",
       "6265  2b4c1b4e-9fa4-4a62-aebd-a6af36663cb4  1.003394  \n",
       "6266  216483f0-dc39-4269-a0e4-42d8689bd75e  1.002992  \n",
       "6267  10aaa832-7334-4e34-805c-87a64adcbc38  1.002810  \n",
       "6268  07987522-106e-4470-bdce-a346faa17bc8  1.002783  \n",
       "6269  2a3a1d34-9d24-43c2-8968-cb8d035f95c1  1.002448  \n",
       "\n",
       "[6270 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "tensorflow"
  },
  "kernelspec": {
   "display_name": "Python (event-recommender)",
   "language": "python",
   "name": "event-recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
